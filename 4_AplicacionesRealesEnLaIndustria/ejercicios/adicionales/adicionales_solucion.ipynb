{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "06c9c221",
      "metadata": {
        "id": "06c9c221"
      },
      "source": [
        "# Ejercicios clase 4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f22870ec",
      "metadata": {
        "id": "f22870ec"
      },
      "source": [
        "## Análisis Frecuentista con Python\n",
        "Realizar el análisis frecuentista en el grupo 1D. Calcular la diferencia de las tasas de conversión, realizar un Test de proporciones para analizar si el efecto es significativo y aplicar el estimador WALD para compensar el ATE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3cda815",
      "metadata": {
        "id": "b3cda815"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "def calcular_diferencia_conversion_rate(dataset):\n",
        "  control = dataset[dataset[\"GRUPO\"] == \"GC\"]\n",
        "  grupo_1D = dataset[dataset[\"GRUPO\"] == \"1D\"]\n",
        "\n",
        "  conversion_rate_control = control[\"Outcome\"].mean()\n",
        "  conversion_rate_1D = grupo_1D[\"Outcome\"].mean()\n",
        "\n",
        "  ATE = conversion_rate_1D - conversion_rate_control\n",
        "  return ATE\n",
        "\n",
        "def test_proporciones(dataset):\n",
        "  control = dataset[dataset[\"GRUPO\"] == \"GC\"]\n",
        "  grupo_1D = dataset[dataset[\"GRUPO\"] == \"1D\"]\n",
        "\n",
        "  conversiones_control = control[\"Outcome\"].sum()\n",
        "  conversiones_1D = grupo_1D[\"Outcome\"].sum()\n",
        "\n",
        "  no_conversiones_control = len(control) - conversiones_control\n",
        "  no_conversiones_1D = len(grupo_1D) - conversiones_1D\n",
        "\n",
        "  contingencia = np.array([[conversiones_control, no_conversiones_control],\n",
        "                          [conversiones_1D, no_conversiones_1D]])\n",
        "\n",
        "  chi2, p_value, dof, ex = chi2_contingency(contingencia)\n",
        "  return p_value\n",
        "\n",
        "def estimador_wald(dataset):\n",
        "  control = dataset[dataset[\"GRUPO\"] == \"GC\"]\n",
        "  grupo_1D = dataset[dataset[\"GRUPO\"] == \"1D\"]\n",
        "\n",
        "  conversion_rate_control_shown = control[control[\"shown\"] == 1][\"Outcome\"].mean()\n",
        "  conversion_rate_1D_shown = grupo_1D[grupo_1D[\"shown\"] == 1][\"Outcome\"].mean()\n",
        "\n",
        "  ATE_WALD = (conversion_rate_1D_shown - conversion_rate_control_shown) / grupo_1D[\"shown\"].mean()\n",
        "  return ATE_WALD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8b2f40b",
      "metadata": {
        "id": "a8b2f40b"
      },
      "source": [
        "## Estimar efecto de largo plazo con S Learner\n",
        "Estimar efecto de largo plazo utilizando la técnica del S learner (con Regresión Lineal) para el grupo 1D."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2d4cbb0",
      "metadata": {
        "id": "a2d4cbb0"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def efecto_largo_plazo_s_learner(dataset):\n",
        "    features = [\"first_purchase_window\", \"freq_rfm\", \"recency\", \"cant_dias_active\", \"recency_date\"]\n",
        "\n",
        "    control = dataset[dataset[\"GRUPO\"] == \"GC\"]\n",
        "    grupo_1D = dataset[dataset[\"GRUPO\"] == \"1D\"]\n",
        "\n",
        "    X_control = control[features]\n",
        "    y_control = control[\"long_Outcome\"]\n",
        "\n",
        "    X_1D = grupo_1D[features]\n",
        "    y_1D = grupo_1D[\"long_Outcome\"]\n",
        "\n",
        "    X = np.concatenate((X_control, X_1D), axis=0)\n",
        "    y = np.concatenate((y_control, y_1D), axis=0)\n",
        "    tratamiento = np.concatenate((np.zeros_like(y_control), np.ones_like(y_1D)), axis=0)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    X_stacked = np.hstack((X, tratamiento.reshape(-1, 1)))\n",
        "\n",
        "    reg = LinearRegression().fit(X_stacked, y)\n",
        "    coef_tratamiento = reg.coef_[-1]\n",
        "\n",
        "    return coef_tratamiento"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}